{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f35755",
   "metadata": {},
   "source": [
    "## 1. Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8d1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f896693",
   "metadata": {},
   "source": [
    "## 2. 평가 함수 정의 (NMAE 집중)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86213a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comovement_nmae(answer_df, submission_df, eps=1e-6):\n",
    "    \"\"\"\n",
    "    전체 U = G ∪ P에 대한 clipped NMAE 계산\n",
    "    NMAE가 낮을수록 좋음 (0에 가까울수록 좋음)\n",
    "    \"\"\"\n",
    "    ans = answer_df[[\"leading_item_id\", \"following_item_id\", \"value\"]].copy()\n",
    "    sub = submission_df[[\"leading_item_id\", \"following_item_id\", \"value\"]].copy()\n",
    "    ans[\"pair\"] = list(zip(ans[\"leading_item_id\"], ans[\"following_item_id\"]))\n",
    "    sub[\"pair\"] = list(zip(sub[\"leading_item_id\"], sub[\"following_item_id\"]))\n",
    "    \n",
    "    G = set(ans[\"pair\"])\n",
    "    P = set(sub[\"pair\"])\n",
    "    U = G | P\n",
    "    \n",
    "    ans_val = dict(zip(ans[\"pair\"], ans[\"value\"]))\n",
    "    sub_val = dict(zip(sub[\"pair\"], sub[\"value\"]))\n",
    "    \n",
    "    errors = []\n",
    "    for pair in U:\n",
    "        if pair in G and pair in P:\n",
    "            # 정수 변환(반올림)\n",
    "            y_true = int(round(float(ans_val[pair])))\n",
    "            y_pred = int(round(float(sub_val[pair])))\n",
    "            rel_err = abs(y_true - y_pred) / (abs(y_true) + eps)\n",
    "            rel_err = min(rel_err, 1.0)  # 오차 100% 이상은 100%로 간주\n",
    "        else:\n",
    "            rel_err = 1.0  # FN, FP는 오차 100%\n",
    "        errors.append(rel_err)\n",
    "    \n",
    "    return np.mean(errors) if errors else 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada050a",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 및 학습/검증 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e63b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 기간: 2022-01-01 00:00:00 ~ 2025-06-01 00:00:00\n",
      "학습 데이터 shape: (100, 42)\n",
      "\n",
      "검증 데이터 날짜: 2025-07-01 00:00:00\n",
      "검증 데이터 shape: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "# year, month, item_id 기준으로 value 합산\n",
    "monthly = (\n",
    "    train\n",
    "    .groupby([\"item_id\", \"year\", \"month\"], as_index=False)[\"value\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# year, month를 하나의 키(ym)로 묶기\n",
    "monthly[\"ym\"] = pd.to_datetime(\n",
    "    monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2)\n",
    ")\n",
    "\n",
    "# item_id × ym 피벗 (월별 총 무역량 매트릭스 생성)\n",
    "pivot = (\n",
    "    monthly\n",
    "    .pivot(index=\"item_id\", columns=\"ym\", values=\"value\")\n",
    "    .fillna(0.0)\n",
    ")\n",
    "\n",
    "# 2025-07-01을 기준으로 학습/검증 분리\n",
    "val_date = pd.to_datetime(\"2025-07-01\")\n",
    "\n",
    "# 학습 데이터: 2025-07-01 이전 데이터만 사용\n",
    "pivot_train = pivot.loc[:, pivot.columns < val_date].copy()\n",
    "print(f\"학습 데이터 기간: {pivot_train.columns.min()} ~ {pivot_train.columns.max()}\")\n",
    "print(f\"학습 데이터 shape: {pivot_train.shape}\")\n",
    "\n",
    "# 검증 데이터: 2025-07-01 데이터\n",
    "if val_date in pivot.columns:\n",
    "    print(f\"\\n검증 데이터 날짜: {val_date}\")\n",
    "    print(f\"검증 데이터 shape: ({pivot.shape[0]}, 1)\")\n",
    "else:\n",
    "    print(f\"\\n경고: {val_date} 데이터가 pivot에 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89204c62",
   "metadata": {},
   "source": [
    "## 4. 공행성쌍 탐색 (학습 데이터만 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4163fef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:11,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탐색된 공행성쌍 수: 1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leading_item_id</th>\n",
       "      <th>following_item_id</th>\n",
       "      <th>best_lag</th>\n",
       "      <th>max_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AANGBULD</td>\n",
       "      <td>APQGTRMF</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.459240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AANGBULD</td>\n",
       "      <td>DEWLVASR</td>\n",
       "      <td>6</td>\n",
       "      <td>0.673163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AANGBULD</td>\n",
       "      <td>DNMPSKTB</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.434721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AANGBULD</td>\n",
       "      <td>EVBVXETX</td>\n",
       "      <td>6</td>\n",
       "      <td>0.453442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AANGBULD</td>\n",
       "      <td>FTSVTTSR</td>\n",
       "      <td>3</td>\n",
       "      <td>0.533976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  leading_item_id following_item_id  best_lag  max_corr\n",
       "0        AANGBULD          APQGTRMF         5 -0.459240\n",
       "1        AANGBULD          DEWLVASR         6  0.673163\n",
       "2        AANGBULD          DNMPSKTB         4 -0.434721\n",
       "3        AANGBULD          EVBVXETX         6  0.453442\n",
       "4        AANGBULD          FTSVTTSR         3  0.533976"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_corr(x, y):\n",
    "    if np.std(x) == 0 or np.std(y) == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "def find_comovement_pairs(\n",
    "    pivot, \n",
    "    max_lag=6, \n",
    "    min_nonzero=12, \n",
    "    corr_threshold=0.4\n",
    "):\n",
    "    items = pivot.index.to_list()\n",
    "    months = pivot.columns.to_list()\n",
    "    n_months = len(months)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, leader in tqdm(enumerate(items)):\n",
    "        x = pivot.loc[leader].values.astype(float)\n",
    "        if np.count_nonzero(x) < min_nonzero:\n",
    "            continue\n",
    "\n",
    "        for follower in items:\n",
    "            if follower == leader:\n",
    "                continue\n",
    "\n",
    "            y = pivot.loc[follower].values.astype(float)\n",
    "            if np.count_nonzero(y) < min_nonzero:\n",
    "                continue\n",
    "\n",
    "            best_lag = None\n",
    "            best_corr = 0.0\n",
    "\n",
    "            # lag = 1 ~ max_lag 탐색\n",
    "            for lag in range(1, max_lag + 1):\n",
    "                if n_months <= lag:\n",
    "                    continue\n",
    "                corr = safe_corr(x[:-lag], y[lag:])\n",
    "                if abs(corr) > abs(best_corr):\n",
    "                    best_corr = corr\n",
    "                    best_lag = lag\n",
    "\n",
    "            # 임계값 이상이면 공행성쌍으로 채택\n",
    "            if best_lag is not None and abs(best_corr) >= corr_threshold:\n",
    "                results.append({\n",
    "                    \"leading_item_id\": leader,\n",
    "                    \"following_item_id\": follower,\n",
    "                    \"best_lag\": best_lag,\n",
    "                    \"max_corr\": best_corr,\n",
    "                })\n",
    "\n",
    "    pairs = pd.DataFrame(results)\n",
    "    return pairs\n",
    "\n",
    "# 학습 데이터로만 공행성쌍 탐색\n",
    "pairs = find_comovement_pairs(pivot_train)\n",
    "print(\"탐색된 공행성쌍 수:\", len(pairs))\n",
    "pairs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d5972",
   "metadata": {},
   "source": [
    "## 5. 고급 Feature Engineering 및 학습 데이터 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01afd24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 학습 데이터의 shape : (54154, 17)\n",
      "Feature 목록: ['b_t', 'b_t_1', 'a_t_lag', 'max_corr', 'best_lag', 'b_t_ma3', 'a_t_lag_ma3', 'b_trend', 'b_trend_2', 'a_trend', 'b_t_scaled', 'a_t_lag_scaled', 'a_t_lag_weighted', 'lag_1', 'lag_2', 'lag_3plus']\n"
     ]
    }
   ],
   "source": [
    "def build_training_data_enhanced(pivot, pairs, use_log_transform=False):\n",
    "    \"\"\"\n",
    "    향상된 Feature Engineering을 적용한 학습 데이터 생성\n",
    "    \"\"\"\n",
    "    months = pivot.columns.to_list()\n",
    "    n_months = len(months)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for row in pairs.itertuples(index=False):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        corr = float(row.max_corr)\n",
    "\n",
    "        if leader not in pivot.index or follower not in pivot.index:\n",
    "            continue\n",
    "\n",
    "        a_series = pivot.loc[leader].values.astype(float)\n",
    "        b_series = pivot.loc[follower].values.astype(float)\n",
    "\n",
    "        # t+1이 존재하고, t-lag >= 0인 구간만 학습에 사용\n",
    "        for t in range(max(lag, 2), n_months - 1):  # 최소 2개월 전 데이터 필요\n",
    "            b_t = b_series[t]\n",
    "            b_t_1 = b_series[t - 1]\n",
    "            b_t_2 = b_series[t - 2] if t >= 2 else 0.0\n",
    "            a_t_lag = a_series[t - lag]\n",
    "            a_t_lag_1 = a_series[t - lag - 1] if t - lag - 1 >= 0 else 0.0\n",
    "            b_t_plus_1 = b_series[t + 1]\n",
    "\n",
    "            # 기본 feature\n",
    "            features = {\n",
    "                \"b_t\": b_t,\n",
    "                \"b_t_1\": b_t_1,\n",
    "                \"a_t_lag\": a_t_lag,\n",
    "                \"max_corr\": corr,\n",
    "                \"best_lag\": float(lag),\n",
    "            }\n",
    "            \n",
    "            # 추가 feature: 이동평균\n",
    "            window = min(3, t + 1)\n",
    "            features[\"b_t_ma3\"] = np.mean(b_series[max(0, t - window + 1):t + 1])\n",
    "            features[\"a_t_lag_ma3\"] = np.mean(a_series[max(0, t - lag - window + 1):t - lag + 1]) if t - lag >= 0 else 0.0\n",
    "            \n",
    "            # 추가 feature: 트렌드 (변화율)\n",
    "            features[\"b_trend\"] = (b_t - b_t_1) / (b_t_1 + 1e-6) if b_t_1 > 0 else 0.0\n",
    "            features[\"b_trend_2\"] = (b_t_1 - b_t_2) / (b_t_2 + 1e-6) if b_t_2 > 0 else 0.0\n",
    "            features[\"a_trend\"] = (a_t_lag - a_t_lag_1) / (a_t_lag_1 + 1e-6) if a_t_lag_1 > 0 else 0.0\n",
    "            \n",
    "            # 추가 feature: 정규화된 값\n",
    "            b_mean = np.mean(b_series[:t+1])\n",
    "            a_mean = np.mean(a_series[:t-lag+1]) if t - lag >= 0 else 1.0\n",
    "            features[\"b_t_scaled\"] = b_t / (b_mean + 1e-6)\n",
    "            features[\"a_t_lag_scaled\"] = a_t_lag / (a_mean + 1e-6)\n",
    "            \n",
    "            # 추가 feature: 상관관계 가중치\n",
    "            features[\"a_t_lag_weighted\"] = a_t_lag * abs(corr)\n",
    "            \n",
    "            # 추가 feature: lag별 특성\n",
    "            features[\"lag_1\"] = 1.0 if lag == 1 else 0.0\n",
    "            features[\"lag_2\"] = 1.0 if lag == 2 else 0.0\n",
    "            features[\"lag_3plus\"] = 1.0 if lag >= 3 else 0.0\n",
    "            \n",
    "            # Target\n",
    "            if use_log_transform:\n",
    "                features[\"target\"] = np.log1p(b_t_plus_1)\n",
    "            else:\n",
    "                features[\"target\"] = b_t_plus_1\n",
    "\n",
    "            rows.append(features)\n",
    "\n",
    "    df_train = pd.DataFrame(rows)\n",
    "    return df_train\n",
    "\n",
    "# 로그 변환 옵션\n",
    "USE_LOG_TRANSFORM = False\n",
    "\n",
    "df_train_model = build_training_data_enhanced(pivot_train, pairs, use_log_transform=USE_LOG_TRANSFORM)\n",
    "print('생성된 학습 데이터의 shape :', df_train_model.shape)\n",
    "print('Feature 목록:', [col for col in df_train_model.columns if col != 'target'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d13205",
   "metadata": {},
   "source": [
    "## 6. 하이퍼파라미터 탐색 공간 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fc0e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 개수: 16\n",
      "학습 샘플 수: 54154\n",
      "\n",
      "하이퍼파라미터 탐색 공간:\n",
      "  n_estimators: [50, 100, 200, 300]\n",
      "  max_depth: [10, 15, 20, 25, None]\n",
      "  min_samples_split: [2, 5, 10]\n",
      "  min_samples_leaf: [1, 2, 4]\n",
      "  max_features: ['sqrt', 'log2', None]\n",
      "\n",
      "총 조합 수: 540\n",
      "\n",
      "RandomizedSearchCV로 50개 조합 탐색 예정\n"
     ]
    }
   ],
   "source": [
    "# Feature 선택\n",
    "feature_cols = [col for col in df_train_model.columns if col != 'target']\n",
    "train_X = df_train_model[feature_cols].values\n",
    "train_y = df_train_model[\"target\"].values\n",
    "\n",
    "print(f\"Feature 개수: {len(feature_cols)}\")\n",
    "print(f\"학습 샘플 수: {len(train_X)}\")\n",
    "\n",
    "# 하이퍼파라미터 탐색 공간 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [10, 15, 20, 25, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "print(\"\\n하이퍼파라미터 탐색 공간:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "print(f\"\\n총 조합 수: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "\n",
    "# RandomizedSearchCV 사용 (GridSearchCV보다 빠름)\n",
    "# n_iter: 랜덤하게 시도할 조합 수\n",
    "n_iter = 50  # 조정 가능\n",
    "print(f\"\\nRandomizedSearchCV로 {n_iter}개 조합 탐색 예정\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462889c",
   "metadata": {},
   "source": [
    "## 7. 하이퍼파라미터 탐색 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbe0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하이퍼파라미터 탐색 시작...\n",
      "(시간이 오래 걸릴 수 있습니다)\n",
      "\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "\n",
      "하이퍼파라미터 탐색 완료!\n",
      "최적 파라미터: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 25}\n",
      "최적 CV 점수 (neg_MAE): -44529.650390\n"
     ]
    }
   ],
   "source": [
    "# 기본 RandomForest 모델\n",
    "base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# RandomizedSearchCV로 하이퍼파라미터 탐색\n",
    "# cv=3: 3-fold cross validation\n",
    "# scoring='neg_mean_absolute_error': MAE를 기준으로 평가 (음수로 반환되므로 최대화)\n",
    "# n_iter: 랜덤하게 시도할 조합 수\n",
    "print(\"하이퍼파라미터 탐색 시작...\")\n",
    "print(\"(시간이 오래 걸릴 수 있습니다)\\n\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=n_iter,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(train_X, train_y)\n",
    "\n",
    "print(\"\\n하이퍼파라미터 탐색 완료!\")\n",
    "print(f\"최적 파라미터: {random_search.best_params_}\")\n",
    "print(f\"최적 CV 점수 (neg_MAE): {random_search.best_score_:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd2e30",
   "metadata": {},
   "source": [
    "## 8. 최적 모델로 예측 함수 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16194d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_model(pivot, pairs, model, feature_cols, target_date, use_log_transform=False):\n",
    "    \"\"\"\n",
    "    단일 모델을 사용한 예측 함수\n",
    "    \"\"\"\n",
    "    # target_date 이전까지의 데이터만 사용\n",
    "    pivot_for_pred = pivot.loc[:, pivot.columns < target_date].copy()\n",
    "    \n",
    "    if len(pivot_for_pred.columns) == 0:\n",
    "        raise ValueError(f\"target_date {target_date} 이전의 데이터가 없습니다.\")\n",
    "    \n",
    "    months = pivot_for_pred.columns.to_list()\n",
    "    n_months = len(months)\n",
    "    \n",
    "    # 가장 마지막 달 index\n",
    "    t_last = n_months - 1\n",
    "    t_prev = t_last - 1 if t_last > 0 else t_last\n",
    "    t_prev2 = t_last - 2 if t_last >= 2 else 0\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for row in tqdm(pairs.itertuples(index=False), desc=\"예측 중\"):\n",
    "        leader = row.leading_item_id\n",
    "        follower = row.following_item_id\n",
    "        lag = int(row.best_lag)\n",
    "        corr = float(row.max_corr)\n",
    "\n",
    "        if leader not in pivot_for_pred.index or follower not in pivot_for_pred.index:\n",
    "            continue\n",
    "\n",
    "        a_series = pivot_for_pred.loc[leader].values.astype(float)\n",
    "        b_series = pivot_for_pred.loc[follower].values.astype(float)\n",
    "\n",
    "        # t_last - lag 가 0 이상인 경우만 예측\n",
    "        if t_last - lag < 0:\n",
    "            continue\n",
    "\n",
    "        # Feature 생성 (학습 시와 동일한 방식)\n",
    "        b_t = b_series[t_last]\n",
    "        b_t_1 = b_series[t_prev] if t_prev >= 0 else 0.0\n",
    "        b_t_2 = b_series[t_prev2] if t_prev2 >= 0 else 0.0\n",
    "        a_t_lag = a_series[t_last - lag]\n",
    "        a_t_lag_1 = a_series[t_last - lag - 1] if t_last - lag - 1 >= 0 else 0.0\n",
    "\n",
    "        # Feature 벡터 생성\n",
    "        features = {\n",
    "            \"b_t\": b_t,\n",
    "            \"b_t_1\": b_t_1,\n",
    "            \"a_t_lag\": a_t_lag,\n",
    "            \"max_corr\": corr,\n",
    "            \"best_lag\": float(lag),\n",
    "            \"b_t_ma3\": np.mean(b_series[max(0, t_last - 2):t_last + 1]),\n",
    "            \"a_t_lag_ma3\": np.mean(a_series[max(0, t_last - lag - 2):t_last - lag + 1]) if t_last - lag >= 0 else 0.0,\n",
    "            \"b_trend\": (b_t - b_t_1) / (b_t_1 + 1e-6) if b_t_1 > 0 else 0.0,\n",
    "            \"b_trend_2\": (b_t_1 - b_t_2) / (b_t_2 + 1e-6) if b_t_2 > 0 else 0.0,\n",
    "            \"a_trend\": (a_t_lag - a_t_lag_1) / (a_t_lag_1 + 1e-6) if a_t_lag_1 > 0 else 0.0,\n",
    "            \"b_t_scaled\": b_t / (np.mean(b_series[:t_last+1]) + 1e-6),\n",
    "            \"a_t_lag_scaled\": a_t_lag / (np.mean(a_series[:t_last-lag+1]) + 1e-6) if t_last - lag >= 0 else 0.0,\n",
    "            \"a_t_lag_weighted\": a_t_lag * abs(corr),\n",
    "            \"lag_1\": 1.0 if lag == 1 else 0.0,\n",
    "            \"lag_2\": 1.0 if lag == 2 else 0.0,\n",
    "            \"lag_3plus\": 1.0 if lag >= 3 else 0.0,\n",
    "        }\n",
    "        \n",
    "        X_test = np.array([[features[col] for col in feature_cols]])\n",
    "\n",
    "        # 단일 모델 예측\n",
    "        y_pred = model.predict(X_test)[0]\n",
    "\n",
    "        # 로그 변환 사용 시 역변환\n",
    "        if use_log_transform:\n",
    "            y_pred = np.expm1(y_pred)\n",
    "\n",
    "        # 후처리: 음수 방지 및 정수 변환\n",
    "        y_pred = max(0.0, float(y_pred))\n",
    "        \n",
    "        # 추가 후처리: 이상치 제한\n",
    "        if b_t > 0:\n",
    "            # 현재 값의 20배를 넘지 않도록 제한\n",
    "            y_pred = min(y_pred, b_t * 20)\n",
    "            # 최근 트렌드 반영 (선택적)\n",
    "            if b_t_1 > 0:\n",
    "                trend = b_t / b_t_1\n",
    "                y_pred = y_pred * (0.7 + 0.3 * min(trend, 2.0))  # 트렌드 반영하되 과도하지 않게\n",
    "        \n",
    "        y_pred = int(round(y_pred))\n",
    "\n",
    "        preds.append({\n",
    "            \"leading_item_id\": leader,\n",
    "            \"following_item_id\": follower,\n",
    "            \"value\": y_pred,\n",
    "        })\n",
    "\n",
    "    df_pred = pd.DataFrame(preds)\n",
    "    return df_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d74f6",
   "metadata": {},
   "source": [
    "## 9. 정답 데이터 생성 (2025-07-01 실제 값)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53de70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 정답 데이터 수: 1453\n",
      "정답 데이터 value 합계: 7,009,633,460\n"
     ]
    }
   ],
   "source": [
    "# train.csv에서 2025-07-01의 실제 데이터 추출\n",
    "val_year = val_date.year\n",
    "val_month = val_date.month\n",
    "\n",
    "answer_raw = train[\n",
    "    (train[\"year\"] == val_year) & \n",
    "    (train[\"month\"] == val_month)\n",
    "].copy()\n",
    "\n",
    "# item_id별 value 합산\n",
    "answer_monthly = (\n",
    "    answer_raw\n",
    "    .groupby(\"item_id\", as_index=False)[\"value\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# 공행성쌍에 대해 정답 생성\n",
    "answer_dict = dict(zip(answer_monthly[\"item_id\"], answer_monthly[\"value\"]))\n",
    "\n",
    "answer_list = []\n",
    "for row in pairs.itertuples(index=False):\n",
    "    follower = row.following_item_id\n",
    "    if follower in answer_dict:\n",
    "        answer_list.append({\n",
    "            \"leading_item_id\": row.leading_item_id,\n",
    "            \"following_item_id\": follower,\n",
    "            \"value\": answer_dict[follower]\n",
    "        })\n",
    "    else:\n",
    "        answer_list.append({\n",
    "            \"leading_item_id\": row.leading_item_id,\n",
    "            \"following_item_id\": follower,\n",
    "            \"value\": 0\n",
    "        })\n",
    "\n",
    "answer_df = pd.DataFrame(answer_list)\n",
    "print(f\"생성된 정답 데이터 수: {len(answer_df)}\")\n",
    "print(f\"정답 데이터 value 합계: {answer_df['value'].sum():,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701e4a5",
   "metadata": {},
   "source": [
    "## 10. 최적 모델로 예측 및 NMAE 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773e466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 최적 하이퍼파라미터 ===\n",
      "  n_estimators: 50\n",
      "  min_samples_split: 2\n",
      "  min_samples_leaf: 1\n",
      "  max_features: None\n",
      "  max_depth: 25\n",
      "\n",
      "=== 최적 모델로 예측 수행 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "예측 중: 1453it [00:28, 51.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 검증 결과 ===\n",
      "NMAE: 0.466018\n",
      "NMAE Score (1 - NMAE): 0.533982\n",
      "\n",
      "목표: NMAE < 0.4 (NMAE Score > 0.6)\n",
      "\n",
      "예측값 통계:\n",
      "count    1.453000e+03\n",
      "mean     3.723056e+06\n",
      "std      1.071332e+07\n",
      "min      5.630000e+02\n",
      "25%      9.396800e+04\n",
      "50%      4.122570e+05\n",
      "75%      3.184892e+06\n",
      "max      1.094731e+08\n",
      "Name: value, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델 가져오기\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "print(\"=== 최적 하이퍼파라미터 ===\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# 최적 모델로 예측\n",
    "print(\"\\n=== 최적 모델로 예측 수행 ===\")\n",
    "submission = predict_single_model(\n",
    "    pivot, \n",
    "    pairs, \n",
    "    best_model, \n",
    "    feature_cols, \n",
    "    val_date,\n",
    "    use_log_transform=USE_LOG_TRANSFORM\n",
    ")\n",
    "\n",
    "# NMAE 계산\n",
    "nmae = comovement_nmae(answer_df, submission)\n",
    "nmae_score = 1 - nmae\n",
    "\n",
    "print(f\"\\n=== 검증 결과 ===\")\n",
    "print(f\"NMAE: {nmae:.6f}\")\n",
    "print(f\"NMAE Score (1 - NMAE): {nmae_score:.6f}\")\n",
    "print(f\"\\n목표: NMAE < 0.4 (NMAE Score > 0.6)\")\n",
    "\n",
    "print(f\"\\n예측값 통계:\")\n",
    "print(submission['value'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df6a49",
   "metadata": {},
   "source": [
    "## 11. 하이퍼파라미터 탐색 결과 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8080e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 상위 10개 하이퍼파라미터 조합 (CV 점수 기준) ===\n",
      "\n",
      "순위 10:\n",
      "  CV 점수 (neg_MAE): -44529.650390 (+/- 11460.377362)\n",
      "  파라미터: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 25}\n",
      "\n",
      "순위 9:\n",
      "  CV 점수 (neg_MAE): -55050.147901 (+/- 13871.026478)\n",
      "  파라미터: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': None}\n",
      "\n",
      "순위 8:\n",
      "  CV 점수 (neg_MAE): -55402.629495 (+/- 13545.255712)\n",
      "  파라미터: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 25}\n",
      "\n",
      "순위 7:\n",
      "  CV 점수 (neg_MAE): -56229.273934 (+/- 13917.054397)\n",
      "  파라미터: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 25}\n",
      "\n",
      "순위 6:\n",
      "  CV 점수 (neg_MAE): -66040.759791 (+/- 16649.895101)\n",
      "  파라미터: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': None}\n",
      "\n",
      "순위 5:\n",
      "  CV 점수 (neg_MAE): -67766.460688 (+/- 16592.388354)\n",
      "  파라미터: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 25}\n",
      "\n",
      "순위 4:\n",
      "  CV 점수 (neg_MAE): -68918.458687 (+/- 17178.800596)\n",
      "  파라미터: {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': None}\n",
      "\n",
      "순위 3:\n",
      "  CV 점수 (neg_MAE): -79439.661191 (+/- 15108.497528)\n",
      "  파라미터: {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 20}\n",
      "\n",
      "순위 2:\n",
      "  CV 점수 (neg_MAE): -80336.457005 (+/- 15213.738821)\n",
      "  파라미터: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 20}\n",
      "\n",
      "순위 1:\n",
      "  CV 점수 (neg_MAE): -85418.489580 (+/- 17362.685242)\n",
      "  파라미터: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 20}\n",
      "\n",
      "\n",
      "=== 파라미터별 성능 분포 ===\n",
      "\n",
      "n_estimators:\n",
      "                       mean            std  count\n",
      "n_estimators                                     \n",
      "50           -291791.863320  156329.155950     11\n",
      "100          -307901.951642  152914.453148     17\n",
      "200          -359711.955262  294827.356154     13\n",
      "300          -367163.579848  192138.736720      9\n",
      "\n",
      "max_depth:\n",
      "                    mean            std  count\n",
      "max_depth                                     \n",
      "20.0      -216507.911809  136303.809741      8\n",
      "25.0      -218910.679822  133337.174130     11\n",
      "15.0      -330260.167241  150578.357987      9\n",
      "10.0      -589967.865839  130866.313661     12\n",
      "\n",
      "min_samples_split:\n",
      "                            mean            std  count\n",
      "min_samples_split                                     \n",
      "10                -285117.841897  187641.994736     19\n",
      "2                 -331113.772287  178524.725698     16\n",
      "5                 -380647.463922  241511.270739     15\n",
      "\n",
      "min_samples_leaf:\n",
      "                           mean            std  count\n",
      "min_samples_leaf                                     \n",
      "2                -244883.324876  183392.313466     19\n",
      "1                -371987.198853  225161.700019     18\n",
      "4                -390478.350728  163556.958327     13\n",
      "\n",
      "max_features:\n",
      "                       mean            std  count\n",
      "max_features                                     \n",
      "log2         -367798.942720  127341.513084     14\n",
      "sqrt         -486247.936403  181111.013262     13\n"
     ]
    }
   ],
   "source": [
    "# 탐색 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "# 상위 10개 결과 출력\n",
    "print(\"=== 상위 10개 하이퍼파라미터 조합 (CV 점수 기준) ===\\n\")\n",
    "top_results = results_df.nlargest(10, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "for idx, row in top_results.iterrows():\n",
    "    print(f\"순위 {len(top_results) - list(top_results.index).index(idx)}:\")\n",
    "    print(f\"  CV 점수 (neg_MAE): {row['mean_test_score']:.6f} (+/- {row['std_test_score']:.6f})\")\n",
    "    print(f\"  파라미터: {row['params']}\")\n",
    "    print()\n",
    "\n",
    "# 파라미터별 중요도 분석\n",
    "print(\"\\n=== 파라미터별 성능 분포 ===\")\n",
    "for param in param_grid.keys():\n",
    "    param_values = []\n",
    "    scores = []\n",
    "    for idx, row in results_df.iterrows():\n",
    "        param_val = row['params'][param]\n",
    "        param_values.append(param_val)\n",
    "        scores.append(row['mean_test_score'])\n",
    "    \n",
    "    param_df = pd.DataFrame({param: param_values, 'score': scores})\n",
    "    param_summary = param_df.groupby(param)['score'].agg(['mean', 'std', 'count'])\n",
    "    print(f\"\\n{param}:\")\n",
    "    print(param_summary.sort_values('mean', ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
