{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 평가 함수 정의 (NMAE 집중)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comovement_nmae(answer_df, submission_df, eps=1e-6):\n",
        "    \"\"\"\n",
        "    전체 U = G ∪ P에 대한 clipped NMAE 계산\n",
        "    NMAE가 낮을수록 좋음 (0에 가까울수록 좋음)\n",
        "    \"\"\"\n",
        "    ans = answer_df[[\"leading_item_id\", \"following_item_id\", \"value\"]].copy()\n",
        "    sub = submission_df[[\"leading_item_id\", \"following_item_id\", \"value\"]].copy()\n",
        "    ans[\"pair\"] = list(zip(ans[\"leading_item_id\"], ans[\"following_item_id\"]))\n",
        "    sub[\"pair\"] = list(zip(sub[\"leading_item_id\"], sub[\"following_item_id\"]))\n",
        "    \n",
        "    G = set(ans[\"pair\"])\n",
        "    P = set(sub[\"pair\"])\n",
        "    U = G | P\n",
        "    \n",
        "    ans_val = dict(zip(ans[\"pair\"], ans[\"value\"]))\n",
        "    sub_val = dict(zip(sub[\"pair\"], sub[\"value\"]))\n",
        "    \n",
        "    errors = []\n",
        "    for pair in U:\n",
        "        if pair in G and pair in P:\n",
        "            # 정수 변환(반올림)\n",
        "            y_true = int(round(float(ans_val[pair])))\n",
        "            y_pred = int(round(float(sub_val[pair])))\n",
        "            rel_err = abs(y_true - y_pred) / (abs(y_true) + eps)\n",
        "            rel_err = min(rel_err, 1.0)  # 오차 100% 이상은 100%로 간주\n",
        "        else:\n",
        "            rel_err = 1.0  # FN, FP는 오차 100%\n",
        "        errors.append(rel_err)\n",
        "    \n",
        "    return np.mean(errors) if errors else 1.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 데이터 전처리 및 학습/검증 분리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터 기간: 2022-01-01 00:00:00 ~ 2025-06-01 00:00:00\n",
            "학습 데이터 shape: (100, 42)\n",
            "\n",
            "검증 데이터 날짜: 2025-07-01 00:00:00\n",
            "검증 데이터 shape: (100, 1)\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('../data/raw/train.csv')\n",
        "\n",
        "# year, month, item_id 기준으로 value 합산\n",
        "monthly = (\n",
        "    train\n",
        "    .groupby([\"item_id\", \"year\", \"month\"], as_index=False)[\"value\"]\n",
        "    .sum()\n",
        ")\n",
        "\n",
        "# year, month를 하나의 키(ym)로 묶기\n",
        "monthly[\"ym\"] = pd.to_datetime(\n",
        "    monthly[\"year\"].astype(str) + \"-\" + monthly[\"month\"].astype(str).str.zfill(2)\n",
        ")\n",
        "\n",
        "# item_id × ym 피벗 (월별 총 무역량 매트릭스 생성)\n",
        "pivot = (\n",
        "    monthly\n",
        "    .pivot(index=\"item_id\", columns=\"ym\", values=\"value\")\n",
        "    .fillna(0.0)\n",
        ")\n",
        "\n",
        "# 2025-07-01을 기준으로 학습/검증 분리\n",
        "val_date = pd.to_datetime(\"2025-07-01\")\n",
        "\n",
        "# 학습 데이터: 2025-07-01 이전 데이터만 사용\n",
        "pivot_train = pivot.loc[:, pivot.columns < val_date].copy()\n",
        "print(f\"학습 데이터 기간: {pivot_train.columns.min()} ~ {pivot_train.columns.max()}\")\n",
        "print(f\"학습 데이터 shape: {pivot_train.shape}\")\n",
        "\n",
        "# 검증 데이터: 2025-07-01 데이터\n",
        "if val_date in pivot.columns:\n",
        "    print(f\"\\n검증 데이터 날짜: {val_date}\")\n",
        "    print(f\"검증 데이터 shape: ({pivot.shape[0]}, 1)\")\n",
        "else:\n",
        "    print(f\"\\n경고: {val_date} 데이터가 pivot에 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 공행성쌍 탐색 (학습 데이터만 사용)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100it [00:09, 10.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "탐색된 공행성쌍 수: 1453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>leading_item_id</th>\n",
              "      <th>following_item_id</th>\n",
              "      <th>best_lag</th>\n",
              "      <th>max_corr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AANGBULD</td>\n",
              "      <td>APQGTRMF</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.459240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AANGBULD</td>\n",
              "      <td>DEWLVASR</td>\n",
              "      <td>6</td>\n",
              "      <td>0.673163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AANGBULD</td>\n",
              "      <td>DNMPSKTB</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.434721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AANGBULD</td>\n",
              "      <td>EVBVXETX</td>\n",
              "      <td>6</td>\n",
              "      <td>0.453442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AANGBULD</td>\n",
              "      <td>FTSVTTSR</td>\n",
              "      <td>3</td>\n",
              "      <td>0.533976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  leading_item_id following_item_id  best_lag  max_corr\n",
              "0        AANGBULD          APQGTRMF         5 -0.459240\n",
              "1        AANGBULD          DEWLVASR         6  0.673163\n",
              "2        AANGBULD          DNMPSKTB         4 -0.434721\n",
              "3        AANGBULD          EVBVXETX         6  0.453442\n",
              "4        AANGBULD          FTSVTTSR         3  0.533976"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def safe_corr(x, y):\n",
        "    if np.std(x) == 0 or np.std(y) == 0:\n",
        "        return 0.0\n",
        "    return float(np.corrcoef(x, y)[0, 1])\n",
        "\n",
        "def find_comovement_pairs(\n",
        "    pivot, \n",
        "    max_lag=6, \n",
        "    min_nonzero=12, \n",
        "    corr_threshold=0.4\n",
        "):\n",
        "    items = pivot.index.to_list()\n",
        "    months = pivot.columns.to_list()\n",
        "    n_months = len(months)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, leader in tqdm(enumerate(items)):\n",
        "        x = pivot.loc[leader].values.astype(float)\n",
        "        if np.count_nonzero(x) < min_nonzero:\n",
        "            continue\n",
        "\n",
        "        for follower in items:\n",
        "            if follower == leader:\n",
        "                continue\n",
        "\n",
        "            y = pivot.loc[follower].values.astype(float)\n",
        "            if np.count_nonzero(y) < min_nonzero:\n",
        "                continue\n",
        "\n",
        "            best_lag = None\n",
        "            best_corr = 0.0\n",
        "\n",
        "            # lag = 1 ~ max_lag 탐색\n",
        "            for lag in range(1, max_lag + 1):\n",
        "                if n_months <= lag:\n",
        "                    continue\n",
        "                corr = safe_corr(x[:-lag], y[lag:])\n",
        "                if abs(corr) > abs(best_corr):\n",
        "                    best_corr = corr\n",
        "                    best_lag = lag\n",
        "\n",
        "            # 임계값 이상이면 공행성쌍으로 채택\n",
        "            if best_lag is not None and abs(best_corr) >= corr_threshold:\n",
        "                results.append({\n",
        "                    \"leading_item_id\": leader,\n",
        "                    \"following_item_id\": follower,\n",
        "                    \"best_lag\": best_lag,\n",
        "                    \"max_corr\": best_corr,\n",
        "                })\n",
        "\n",
        "    pairs = pd.DataFrame(results)\n",
        "    return pairs\n",
        "\n",
        "# 학습 데이터로만 공행성쌍 탐색\n",
        "pairs = find_comovement_pairs(pivot_train)\n",
        "print(\"탐색된 공행성쌍 수:\", len(pairs))\n",
        "pairs.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 고급 Feature Engineering 및 학습 데이터 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "생성된 학습 데이터의 shape : (54154, 17)\n",
            "Feature 목록: ['b_t', 'b_t_1', 'a_t_lag', 'max_corr', 'best_lag', 'b_t_ma3', 'a_t_lag_ma3', 'b_trend', 'b_trend_2', 'a_trend', 'b_t_scaled', 'a_t_lag_scaled', 'a_t_lag_weighted', 'lag_1', 'lag_2', 'lag_3plus']\n"
          ]
        }
      ],
      "source": [
        "def build_training_data_enhanced(pivot, pairs, use_log_transform=False):\n",
        "    \"\"\"\n",
        "    향상된 Feature Engineering을 적용한 학습 데이터 생성\n",
        "    \"\"\"\n",
        "    months = pivot.columns.to_list()\n",
        "    n_months = len(months)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for row in pairs.itertuples(index=False):\n",
        "        leader = row.leading_item_id\n",
        "        follower = row.following_item_id\n",
        "        lag = int(row.best_lag)\n",
        "        corr = float(row.max_corr)\n",
        "\n",
        "        if leader not in pivot.index or follower not in pivot.index:\n",
        "            continue\n",
        "\n",
        "        a_series = pivot.loc[leader].values.astype(float)\n",
        "        b_series = pivot.loc[follower].values.astype(float)\n",
        "\n",
        "        # t+1이 존재하고, t-lag >= 0인 구간만 학습에 사용\n",
        "        for t in range(max(lag, 2), n_months - 1):  # 최소 2개월 전 데이터 필요\n",
        "            b_t = b_series[t]\n",
        "            b_t_1 = b_series[t - 1]\n",
        "            b_t_2 = b_series[t - 2] if t >= 2 else 0.0\n",
        "            a_t_lag = a_series[t - lag]\n",
        "            a_t_lag_1 = a_series[t - lag - 1] if t - lag - 1 >= 0 else 0.0\n",
        "            b_t_plus_1 = b_series[t + 1]\n",
        "\n",
        "            # 기본 feature\n",
        "            features = {\n",
        "                \"b_t\": b_t,\n",
        "                \"b_t_1\": b_t_1,\n",
        "                \"a_t_lag\": a_t_lag,\n",
        "                \"max_corr\": corr,\n",
        "                \"best_lag\": float(lag),\n",
        "            }\n",
        "            \n",
        "            # 추가 feature: 이동평균\n",
        "            window = min(3, t + 1)\n",
        "            features[\"b_t_ma3\"] = np.mean(b_series[max(0, t - window + 1):t + 1])\n",
        "            features[\"a_t_lag_ma3\"] = np.mean(a_series[max(0, t - lag - window + 1):t - lag + 1]) if t - lag >= 0 else 0.0\n",
        "            \n",
        "            # 추가 feature: 트렌드 (변화율)\n",
        "            features[\"b_trend\"] = (b_t - b_t_1) / (b_t_1 + 1e-6) if b_t_1 > 0 else 0.0\n",
        "            features[\"b_trend_2\"] = (b_t_1 - b_t_2) / (b_t_2 + 1e-6) if b_t_2 > 0 else 0.0\n",
        "            features[\"a_trend\"] = (a_t_lag - a_t_lag_1) / (a_t_lag_1 + 1e-6) if a_t_lag_1 > 0 else 0.0\n",
        "            \n",
        "            # 추가 feature: 정규화된 값\n",
        "            b_mean = np.mean(b_series[:t+1])\n",
        "            a_mean = np.mean(a_series[:t-lag+1]) if t - lag >= 0 else 1.0\n",
        "            features[\"b_t_scaled\"] = b_t / (b_mean + 1e-6)\n",
        "            features[\"a_t_lag_scaled\"] = a_t_lag / (a_mean + 1e-6)\n",
        "            \n",
        "            # 추가 feature: 상관관계 가중치\n",
        "            features[\"a_t_lag_weighted\"] = a_t_lag * abs(corr)\n",
        "            \n",
        "            # 추가 feature: lag별 특성\n",
        "            features[\"lag_1\"] = 1.0 if lag == 1 else 0.0\n",
        "            features[\"lag_2\"] = 1.0 if lag == 2 else 0.0\n",
        "            features[\"lag_3plus\"] = 1.0 if lag >= 3 else 0.0\n",
        "            \n",
        "            # Target\n",
        "            if use_log_transform:\n",
        "                features[\"target\"] = np.log1p(b_t_plus_1)\n",
        "            else:\n",
        "                features[\"target\"] = b_t_plus_1\n",
        "\n",
        "            rows.append(features)\n",
        "\n",
        "    df_train = pd.DataFrame(rows)\n",
        "    return df_train\n",
        "\n",
        "# 로그 변환 옵션\n",
        "USE_LOG_TRANSFORM = False\n",
        "\n",
        "df_train_model = build_training_data_enhanced(pivot_train, pairs, use_log_transform=USE_LOG_TRANSFORM)\n",
        "print('생성된 학습 데이터의 shape :', df_train_model.shape)\n",
        "print('Feature 목록:', [col for col in df_train_model.columns if col != 'target'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 하이퍼파라미터 탐색 공간 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 개수: 16\n",
            "학습 샘플 수: 54154\n",
            "\n",
            "하이퍼파라미터 탐색 공간:\n",
            "  alpha: [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 50.0, 100.0]\n",
            "\n",
            "총 조합 수: 10\n",
            "\n",
            "GridSearchCV로 모든 조합 탐색 예정\n"
          ]
        }
      ],
      "source": [
        "# Feature 선택\n",
        "feature_cols = [col for col in df_train_model.columns if col != 'target']\n",
        "train_X = df_train_model[feature_cols].values\n",
        "train_y = df_train_model[\"target\"].values\n",
        "\n",
        "print(f\"Feature 개수: {len(feature_cols)}\")\n",
        "print(f\"학습 샘플 수: {len(train_X)}\")\n",
        "\n",
        "# 하이퍼파라미터 탐색 공간 정의 (Lasso는 alpha만 조정)\n",
        "param_grid = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 50.0, 100.0]\n",
        "}\n",
        "\n",
        "print(\"\\n하이퍼파라미터 탐색 공간:\")\n",
        "for param, values in param_grid.items():\n",
        "    print(f\"  {param}: {values}\")\n",
        "print(f\"\\n총 조합 수: {len(param_grid['alpha'])}\")\n",
        "\n",
        "# Lasso는 파라미터가 단순하므로 GridSearchCV 사용\n",
        "print(\"\\nGridSearchCV로 모든 조합 탐색 예정\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 하이퍼파라미터 탐색 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "하이퍼파라미터 탐색 시작...\n",
            "\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "\n",
            "하이퍼파라미터 탐색 완료!\n",
            "최적 파라미터: {'alpha': 100.0}\n",
            "최적 CV 점수 (neg_MAE): -1449686.987764\n"
          ]
        }
      ],
      "source": [
        "# 기본 Lasso 모델\n",
        "base_model = Lasso(max_iter=2000)  # max_iter 증가 (수렴 보장)\n",
        "\n",
        "# GridSearchCV로 하이퍼파라미터 탐색\n",
        "print(\"하이퍼파라미터 탐색 시작...\\n\")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(train_X, train_y)\n",
        "\n",
        "print(\"\\n하이퍼파라미터 탐색 완료!\")\n",
        "print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
        "print(f\"최적 CV 점수 (neg_MAE): {grid_search.best_score_:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 최적 모델로 예측 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_single_model(pivot, pairs, model, feature_cols, target_date, use_log_transform=False):\n",
        "    \"\"\"\n",
        "    단일 모델을 사용한 예측 함수\n",
        "    \"\"\"\n",
        "    # target_date 이전까지의 데이터만 사용\n",
        "    pivot_for_pred = pivot.loc[:, pivot.columns < target_date].copy()\n",
        "    \n",
        "    if len(pivot_for_pred.columns) == 0:\n",
        "        raise ValueError(f\"target_date {target_date} 이전의 데이터가 없습니다.\")\n",
        "    \n",
        "    months = pivot_for_pred.columns.to_list()\n",
        "    n_months = len(months)\n",
        "    \n",
        "    # 가장 마지막 달 index\n",
        "    t_last = n_months - 1\n",
        "    t_prev = t_last - 1 if t_last > 0 else t_last\n",
        "    t_prev2 = t_last - 2 if t_last >= 2 else 0\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    for row in tqdm(pairs.itertuples(index=False), desc=\"예측 중\"):\n",
        "        leader = row.leading_item_id\n",
        "        follower = row.following_item_id\n",
        "        lag = int(row.best_lag)\n",
        "        corr = float(row.max_corr)\n",
        "\n",
        "        if leader not in pivot_for_pred.index or follower not in pivot_for_pred.index:\n",
        "            continue\n",
        "\n",
        "        a_series = pivot_for_pred.loc[leader].values.astype(float)\n",
        "        b_series = pivot_for_pred.loc[follower].values.astype(float)\n",
        "\n",
        "        # t_last - lag 가 0 이상인 경우만 예측\n",
        "        if t_last - lag < 0:\n",
        "            continue\n",
        "\n",
        "        # Feature 생성 (학습 시와 동일한 방식)\n",
        "        b_t = b_series[t_last]\n",
        "        b_t_1 = b_series[t_prev] if t_prev >= 0 else 0.0\n",
        "        b_t_2 = b_series[t_prev2] if t_prev2 >= 0 else 0.0\n",
        "        a_t_lag = a_series[t_last - lag]\n",
        "        a_t_lag_1 = a_series[t_last - lag - 1] if t_last - lag - 1 >= 0 else 0.0\n",
        "\n",
        "        # Feature 벡터 생성\n",
        "        features = {\n",
        "            \"b_t\": b_t,\n",
        "            \"b_t_1\": b_t_1,\n",
        "            \"a_t_lag\": a_t_lag,\n",
        "            \"max_corr\": corr,\n",
        "            \"best_lag\": float(lag),\n",
        "            \"b_t_ma3\": np.mean(b_series[max(0, t_last - 2):t_last + 1]),\n",
        "            \"a_t_lag_ma3\": np.mean(a_series[max(0, t_last - lag - 2):t_last - lag + 1]) if t_last - lag >= 0 else 0.0,\n",
        "            \"b_trend\": (b_t - b_t_1) / (b_t_1 + 1e-6) if b_t_1 > 0 else 0.0,\n",
        "            \"b_trend_2\": (b_t_1 - b_t_2) / (b_t_2 + 1e-6) if b_t_2 > 0 else 0.0,\n",
        "            \"a_trend\": (a_t_lag - a_t_lag_1) / (a_t_lag_1 + 1e-6) if a_t_lag_1 > 0 else 0.0,\n",
        "            \"b_t_scaled\": b_t / (np.mean(b_series[:t_last+1]) + 1e-6),\n",
        "            \"a_t_lag_scaled\": a_t_lag / (np.mean(a_series[:t_last-lag+1]) + 1e-6) if t_last - lag >= 0 else 0.0,\n",
        "            \"a_t_lag_weighted\": a_t_lag * abs(corr),\n",
        "            \"lag_1\": 1.0 if lag == 1 else 0.0,\n",
        "            \"lag_2\": 1.0 if lag == 2 else 0.0,\n",
        "            \"lag_3plus\": 1.0 if lag >= 3 else 0.0,\n",
        "        }\n",
        "        \n",
        "        X_test = np.array([[features[col] for col in feature_cols]])\n",
        "\n",
        "        # 단일 모델 예측\n",
        "        y_pred = model.predict(X_test)[0]\n",
        "\n",
        "        # 로그 변환 사용 시 역변환\n",
        "        if use_log_transform:\n",
        "            y_pred = np.expm1(y_pred)\n",
        "\n",
        "        # 후처리: 음수 방지 및 정수 변환\n",
        "        y_pred = max(0.0, float(y_pred))\n",
        "        \n",
        "        # 추가 후처리: 이상치 제한\n",
        "        if b_t > 0:\n",
        "            # 현재 값의 20배를 넘지 않도록 제한\n",
        "            y_pred = min(y_pred, b_t * 20)\n",
        "            # 최근 트렌드 반영 (선택적)\n",
        "            if b_t_1 > 0:\n",
        "                trend = b_t / b_t_1\n",
        "                y_pred = y_pred * (0.7 + 0.3 * min(trend, 2.0))  # 트렌드 반영하되 과도하지 않게\n",
        "        \n",
        "        y_pred = int(round(y_pred))\n",
        "\n",
        "        preds.append({\n",
        "            \"leading_item_id\": leader,\n",
        "            \"following_item_id\": follower,\n",
        "            \"value\": y_pred,\n",
        "        })\n",
        "\n",
        "    df_pred = pd.DataFrame(preds)\n",
        "    return df_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 정답 데이터 생성 (2025-07-01 실제 값)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "생성된 정답 데이터 수: 1453\n",
            "정답 데이터 value 합계: 7,009,633,460\n"
          ]
        }
      ],
      "source": [
        "# train.csv에서 2025-07-01의 실제 데이터 추출\n",
        "val_year = val_date.year\n",
        "val_month = val_date.month\n",
        "\n",
        "answer_raw = train[\n",
        "    (train[\"year\"] == val_year) & \n",
        "    (train[\"month\"] == val_month)\n",
        "].copy()\n",
        "\n",
        "# item_id별 value 합산\n",
        "answer_monthly = (\n",
        "    answer_raw\n",
        "    .groupby(\"item_id\", as_index=False)[\"value\"]\n",
        "    .sum()\n",
        ")\n",
        "\n",
        "# 공행성쌍에 대해 정답 생성\n",
        "answer_dict = dict(zip(answer_monthly[\"item_id\"], answer_monthly[\"value\"]))\n",
        "\n",
        "answer_list = []\n",
        "for row in pairs.itertuples(index=False):\n",
        "    follower = row.following_item_id\n",
        "    if follower in answer_dict:\n",
        "        answer_list.append({\n",
        "            \"leading_item_id\": row.leading_item_id,\n",
        "            \"following_item_id\": follower,\n",
        "            \"value\": answer_dict[follower]\n",
        "        })\n",
        "    else:\n",
        "        answer_list.append({\n",
        "            \"leading_item_id\": row.leading_item_id,\n",
        "            \"following_item_id\": follower,\n",
        "            \"value\": 0\n",
        "        })\n",
        "\n",
        "answer_df = pd.DataFrame(answer_list)\n",
        "print(f\"생성된 정답 데이터 수: {len(answer_df)}\")\n",
        "print(f\"정답 데이터 value 합계: {answer_df['value'].sum():,.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 최적 모델로 예측 및 NMAE 평가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 최적 하이퍼파라미터 ===\n",
            "  alpha: 100.0\n",
            "\n",
            "=== 최적 모델로 예측 수행 ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "예측 중: 1453it [00:00, 3072.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 검증 결과 ===\n",
            "NMAE: 0.566999\n",
            "NMAE Score (1 - NMAE): 0.433001\n",
            "\n",
            "목표: NMAE < 0.4 (NMAE Score > 0.6)\n",
            "\n",
            "예측값 통계:\n",
            "count    1.453000e+03\n",
            "mean     3.790396e+06\n",
            "std      1.053090e+07\n",
            "min      0.000000e+00\n",
            "25%      2.301590e+05\n",
            "50%      5.390360e+05\n",
            "75%      3.153967e+06\n",
            "max      1.089779e+08\n",
            "Name: value, dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 최적 모델 가져오기\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"=== 최적 하이퍼파라미터 ===\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "# 최적 모델로 예측\n",
        "print(\"\\n=== 최적 모델로 예측 수행 ===\")\n",
        "submission = predict_single_model(\n",
        "    pivot, \n",
        "    pairs, \n",
        "    best_model, \n",
        "    feature_cols, \n",
        "    val_date,\n",
        "    use_log_transform=USE_LOG_TRANSFORM\n",
        ")\n",
        "\n",
        "# NMAE 계산\n",
        "nmae = comovement_nmae(answer_df, submission)\n",
        "nmae_score = 1 - nmae\n",
        "\n",
        "print(f\"\\n=== 검증 결과 ===\")\n",
        "print(f\"NMAE: {nmae:.6f}\")\n",
        "print(f\"NMAE Score (1 - NMAE): {nmae_score:.6f}\")\n",
        "print(f\"\\n목표: NMAE < 0.4 (NMAE Score > 0.6)\")\n",
        "\n",
        "print(f\"\\n예측값 통계:\")\n",
        "print(submission['value'].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 하이퍼파라미터 탐색 결과 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 모든 하이퍼파라미터 조합 결과 (CV 점수 기준) ===\n",
            "\n",
            "순위 1:\n",
            "  CV 점수 (neg_MAE): -1449686.987764 (+/- 104892.393985)\n",
            "  파라미터: {'alpha': 100.0}\n",
            "\n",
            "순위 2:\n",
            "  CV 점수 (neg_MAE): -1449732.199826 (+/- 104893.520886)\n",
            "  파라미터: {'alpha': 50.0}\n",
            "\n",
            "순위 3:\n",
            "  CV 점수 (neg_MAE): -1449768.513520 (+/- 104894.425310)\n",
            "  파라미터: {'alpha': 10.0}\n",
            "\n",
            "순위 4:\n",
            "  CV 점수 (neg_MAE): -1449773.055743 (+/- 104894.538380)\n",
            "  파라미터: {'alpha': 5.0}\n",
            "\n",
            "순위 5:\n",
            "  CV 점수 (neg_MAE): -1449775.586978 (+/- 104894.841358)\n",
            "  파라미터: {'alpha': 2.0}\n",
            "\n",
            "순위 6:\n",
            "  CV 점수 (neg_MAE): -1449776.649715 (+/- 104894.744682)\n",
            "  파라미터: {'alpha': 1.0}\n",
            "\n",
            "순위 7:\n",
            "  CV 점수 (neg_MAE): -1449777.163929 (+/- 104894.747365)\n",
            "  파라미터: {'alpha': 0.5}\n",
            "\n",
            "순위 8:\n",
            "  CV 점수 (neg_MAE): -1449777.511659 (+/- 104894.670626)\n",
            "  파라미터: {'alpha': 0.1}\n",
            "\n",
            "순위 9:\n",
            "  CV 점수 (neg_MAE): -1449777.589898 (+/- 104894.653360)\n",
            "  파라미터: {'alpha': 0.01}\n",
            "\n",
            "순위 10:\n",
            "  CV 점수 (neg_MAE): -1449777.597722 (+/- 104894.651633)\n",
            "  파라미터: {'alpha': 0.001}\n",
            "\n",
            "\n",
            "=== alpha별 성능 분포 ===\n",
            "  alpha         score\n",
            "  0.001 -1.449778e+06\n",
            "  0.010 -1.449778e+06\n",
            "  0.100 -1.449778e+06\n",
            "  0.500 -1.449777e+06\n",
            "  1.000 -1.449777e+06\n",
            "  2.000 -1.449776e+06\n",
            "  5.000 -1.449773e+06\n",
            " 10.000 -1.449769e+06\n",
            " 50.000 -1.449732e+06\n",
            "100.000 -1.449687e+06\n"
          ]
        }
      ],
      "source": [
        "# 탐색 결과를 DataFrame으로 변환\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "# 모든 결과 출력 (alpha 값이 적으므로)\n",
        "print(\"=== 모든 하이퍼파라미터 조합 결과 (CV 점수 기준) ===\\n\")\n",
        "results_sorted = results_df.sort_values('mean_test_score', ascending=False)[['params', 'mean_test_score', 'std_test_score']]\n",
        "\n",
        "for idx, row in results_sorted.iterrows():\n",
        "    rank = list(results_sorted.index).index(idx) + 1\n",
        "    print(f\"순위 {rank}:\")\n",
        "    print(f\"  CV 점수 (neg_MAE): {row['mean_test_score']:.6f} (+/- {row['std_test_score']:.6f})\")\n",
        "    print(f\"  파라미터: {row['params']}\")\n",
        "    print()\n",
        "\n",
        "# alpha별 성능 분석\n",
        "print(\"\\n=== alpha별 성능 분포 ===\")\n",
        "alpha_values = []\n",
        "scores = []\n",
        "for idx, row in results_df.iterrows():\n",
        "    alpha_val = row['params']['alpha']\n",
        "    alpha_values.append(alpha_val)\n",
        "    scores.append(row['mean_test_score'])\n",
        "\n",
        "alpha_df = pd.DataFrame({'alpha': alpha_values, 'score': scores})\n",
        "alpha_summary = alpha_df.sort_values('alpha')\n",
        "print(alpha_summary.to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
